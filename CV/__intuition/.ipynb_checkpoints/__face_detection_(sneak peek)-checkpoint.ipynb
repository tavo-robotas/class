{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection with Viola - Jones algorithm\n",
    "\n",
    "[Publication](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.10.6807&rep=rep1&type=pdf)\n",
    "\n",
    "### VJ algorithm\n",
    "\n",
    "What it is, who did it, how it is till these days such a powerful figure even though it was created more than 10 years ago.\n",
    "\n",
    "\n",
    "### Haar like features\n",
    "That are the foundation of Viola - Jones algorithm.\n",
    "\n",
    "\n",
    "### Integral Image\n",
    "A quite usefull hack used in VJ algorthim. Part of the success of the algorithm can be attributed to this integral image technique\n",
    "\n",
    "### Training classifiers\n",
    "How the training process happens in a nutshell\n",
    "\n",
    "\n",
    "### Adaptive boosting (Adaboost)\n",
    "Another usefull hack that helps VJ algorithm in its sucess\n",
    "\n",
    "### Cascading\n",
    "Ant yet another hack which really speeds up the VJ algorithm \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>**And here it is. Ridiculious right !? How small and optimized it is**</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "fcc     = cv2.VideoWriter_fourcc(*'XVID') ## *'XVID' is equal to bytes ('X', 'V', 'I', 'D')\n",
    "output  = cv2.VideoWriter('me.avi', fcc, 20, (1920, 1080), 0)\n",
    "\n",
    "face = cv2.CascadeClassifier('../xml_config/face.xml')\n",
    "eye = cv2.CascadeClassifier('../xml_config/eye.xml')\n",
    "def detect(gray, frame):\n",
    "    faces = face.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye.detectMultiScale(roi_gray, 1.1, 3)\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "    return frame\n",
    "source = '../images/application/v16.mp4'\n",
    "capture = cv2.VideoCapture(source)\n",
    "while capture.isOpened():\n",
    "    retval, frame = capture.read()\n",
    "    if retval:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        canvas = detect(gray, frame)\n",
    "        output.write(canvas)\n",
    "        cv2.imshow('testas', canvas)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27 or key == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "MODE = \"COCO\"\n",
    "\n",
    "if MODE is \"COCO\":\n",
    "    protoFile = \"pose/coco/pose_deploy_linevec.prototxt\"\n",
    "    weightsFile = \"pose/coco/pose_iter_440000.caffemodel\"\n",
    "    nPoints = 18\n",
    "    POSE_PAIRS = [ [1,0],[1,2],[1,5],[2,3],[3,4],[5,6],[6,7],[1,8],[8,9],[9,10],[1,11],[11,12],[12,13],[0,14],[0,15],[14,16],[15,17]]\n",
    "\n",
    "elif MODE is \"MPI\" :\n",
    "    protoFile = \"pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "    weightsFile = \"pose/mpi/pose_iter_160000.caffemodel\"\n",
    "    nPoints = 15\n",
    "    POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ]\n",
    "\n",
    "\n",
    "inWidth = 368\n",
    "inHeight = 368\n",
    "threshold = 0.1\n",
    "\n",
    "\n",
    "input_source = '../images/application/v16.mp4'\n",
    "cap = cv2.VideoCapture(input_source)\n",
    "hasFrame, frame = cap.read()\n",
    "\n",
    "vid_writer = cv2.VideoWriter('output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame.shape[1],frame.shape[0]))\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)\n",
    "# if args.device == \"cpu\":\n",
    "#     net.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)\n",
    "#     print(\"Using CPU device\")\n",
    "# elif args.device == \"gpu\":\n",
    "#     net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "#     net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "#     print(\"Using GPU device\")\n",
    "\n",
    "while cv2.waitKey(1) < 0:\n",
    "    t = time.time()\n",
    "    hasFrame, frame = cap.read()\n",
    "    frameCopy = np.copy(frame)\n",
    "    if not hasFrame:\n",
    "        cv2.waitKey()\n",
    "        break\n",
    "\n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "\n",
    "    inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight),\n",
    "                              (0, 0, 0), swapRB=False, crop=False)\n",
    "    net.setInput(inpBlob)\n",
    "    output = net.forward()\n",
    "\n",
    "    H = output.shape[2]\n",
    "    W = output.shape[3]\n",
    "    # Empty list to store the detected keypoints\n",
    "    points = []\n",
    "\n",
    "    for i in range(nPoints):\n",
    "        # confidence map of corresponding body's part.\n",
    "        probMap = output[0, i, :, :]\n",
    "\n",
    "        # Find global maxima of the probMap.\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "        \n",
    "        # Scale the point to fit on the original image\n",
    "        x = (frameWidth * point[0]) / W\n",
    "        y = (frameHeight * point[1]) / H\n",
    "\n",
    "        if prob > threshold : \n",
    "            cv2.circle(frameCopy, (int(x), int(y)), 8, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frameCopy, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "            # Add the point to the list if the probability is greater than the threshold\n",
    "            points.append((int(x), int(y)))\n",
    "        else :\n",
    "            points.append(None)\n",
    "\n",
    "    # Draw Skeleton\n",
    "    for pair in POSE_PAIRS:\n",
    "        partA = pair[0]\n",
    "        partB = pair[1]\n",
    "\n",
    "        if points[partA] and points[partB]:\n",
    "            cv2.line(frame, points[partA], points[partB], (0, 255, 255), 3, lineType=cv2.LINE_AA)\n",
    "            cv2.circle(frame, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.circle(frame, points[partB], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "\n",
    "    cv2.putText(frame, \"time taken = {:.2f} sec\".format(time.time() - t), (50, 50), cv2.FONT_HERSHEY_COMPLEX, .8, (255, 50, 0), 2, lineType=cv2.LINE_AA)\n",
    "    # cv2.putText(frame, \"OpenPose using OpenCV\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 50, 0), 2, lineType=cv2.LINE_AA)\n",
    "    # cv2.imshow('Output-Keypoints', frameCopy)\n",
    "    cv2.imshow('Output-Skeleton', frame)\n",
    "\n",
    "    vid_writer.write(frame)\n",
    "\n",
    "vid_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken in forward pass = 5.484325408935547\n",
      "Keypoints - Nose : [(1357, 395, 0.83961654), (1511, 394, 0.8457444), (875, 377, 0.89219743), (1203, 376, 0.9195708), (1049, 376, 0.8862472), (124, 357, 0.8259002), (510, 357, 0.9614575), (318, 357, 0.82352173), (683, 338, 0.856123), (1415, 261, 0.88226146), (1280, 260, 0.90032023), (779, 260, 0.90607846), (1568, 259, 0.73647887), (627, 259, 0.7225839), (415, 259, 0.7349052), (1165, 242, 0.78998643), (143, 241, 0.82180446), (895, 241, 0.9291296), (260, 240, 0.796219), (1050, 223, 0.74056864)]\n",
      "Keypoints - Neck : [(1531, 453, 0.8429663), (1376, 436, 0.8604484), (1204, 435, 0.8627519), (1048, 435, 0.84374857), (876, 434, 1.0306513), (317, 433, 0.8833965), (105, 433, 0.7670166), (510, 415, 0.94417274), (682, 415, 0.8502023), (1434, 337, 0.8167788), (779, 319, 0.87838995), (1300, 318, 0.76918155), (1570, 318, 0.8274094), (625, 318, 0.82719684), (414, 318, 0.8535441), (1184, 301, 0.58250415), (106, 317, 0.5187622), (914, 300, 0.80126023), (260, 299, 0.8526006), (1050, 298, 0.69522506)]\n",
      "Keypoints - R-Sho : [(1473, 453, 0.80075943), (1146, 436, 0.78995603), (1319, 435, 0.81895417), (991, 435, 0.8401166), (818, 435, 0.93451595), (48, 434, 0.7532748), (259, 416, 0.83231604), (452, 415, 0.8623605), (625, 415, 0.90203416), (1376, 319, 0.61966693), (722, 319, 0.7771923), (1512, 319, 0.75340366), (1260, 318, 0.56073654), (567, 318, 0.8336712), (1145, 318, 0.5136971), (374, 318, 0.69828737), (857, 318, 0.7220777), (67, 301, 0.51847273), (202, 299, 0.8595987), (1010, 299, 0.7099091)]\n",
      "Keypoints - R-Elb : [(1453, 532, 0.4677741), (88, 531, 0.6174236), (972, 530, 0.5729581), (1300, 530, 0.7187061), (1127, 530, 0.64000624), (240, 512, 0.85942096), (607, 511, 0.6304923), (433, 493, 0.8165092), (780, 493, 0.8231959), (703, 414, 0.13443018), (549, 396, 0.25760368), (838, 376, 0.18215105), (201, 396, 0.56512666), (356, 396, 0.28979993), (991, 376, 0.23747855)]\n",
      "Keypoints - R-Wr : [(1491, 570, 0.3629553), (1300, 569, 0.5674461), (1164, 551, 0.37911507), (644, 550, 0.50880986), (452, 550, 0.9321782), (183, 531, 0.6736264), (316, 531, 0.78904784), (838, 531, 0.903607)]\n",
      "Keypoints - L-Sho : [(1434, 452, 0.8032968), (1589, 436, 0.66607964), (1262, 435, 0.81330454), (1089, 435, 0.7815312), (934, 434, 0.99643683), (376, 433, 0.7867784), (145, 415, 0.74972546), (567, 415, 0.8780596), (722, 415, 0.80665433), (1491, 338, 0.64957845), (819, 319, 0.6861696), (1339, 318, 0.5965216), (682, 318, 0.54757696), (1627, 318, 0.80430436), (145, 318, 0.53473276), (471, 318, 0.77306193), (1223, 300, 0.5382882), (954, 300, 0.6752692), (318, 299, 0.7047095), (1108, 299, 0.7029006)]\n",
      "Keypoints - L-Elb : [(1626, 550, 0.7136971), (1433, 531, 0.7718975), (1280, 531, 0.6790918), (1126, 512, 0.58388656), (953, 512, 0.81349254), (395, 512, 0.81051195), (183, 511, 0.5707552), (586, 511, 0.745759), (741, 492, 0.5277208), (837, 415, 0.3531491), (1664, 415, 0.6767049), (318, 377, 0.11665505), (972, 396, 0.7008956), (509, 357, 0.12570365), (1125, 377, 0.429976)]\n",
      "Keypoints - L-Wr : [(1549, 570, 0.7029351), (1357, 569, 0.8250667), (1224, 551, 0.47447798), (722, 551, 0.449791), (568, 551, 0.7577194), (1088, 550, 0.68462646), (201, 531, 0.25154114), (356, 531, 0.5945391), (895, 531, 0.73965186), (1627, 492, 0.36908206), (972, 434, 0.16754887)]\n",
      "Keypoints - R-Hip : [(1492, 608, 0.4979629), (105, 589, 0.54044867), (1337, 589, 0.5728518), (1165, 588, 0.61860013), (472, 570, 0.63464886), (1010, 570, 0.6669514), (280, 570, 0.5953459), (838, 552, 0.6103889), (645, 551, 0.59712106), (1394, 472, 0.10083255), (741, 474, 0.55816156), (1532, 473, 0.23935188), (240, 473, 0.44131422), (587, 454, 0.28578705), (376, 454, 0.34934488), (876, 434, 0.19144256)]\n",
      "Keypoints - R-Knee : [(1492, 666, 0.6151696), (472, 628, 0.26905885), (1165, 590, 0.12847075), (644, 608, 0.3062776), (1319, 589, 0.70603776), (1069, 589, 0.67676604), (356, 588, 0.5246696), (876, 588, 0.50753975), (741, 568, 0.17423975), (203, 569, 0.70891553)]\n",
      "Keypoints - R-Ank : [(1492, 802, 0.68946177), (1184, 763, 0.111375265), (1319, 764, 0.59815955), (1068, 763, 0.70956564), (857, 762, 0.70631737), (645, 744, 0.27671474), (221, 744, 0.6148206), (413, 725, 0.4855458)]\n",
      "Keypoints - L-Hip : [(1570, 627, 0.4766653), (1396, 589, 0.61087286), (1242, 570, 0.59762454), (548, 570, 0.6727922), (163, 569, 0.48601973), (1069, 569, 0.5441228), (375, 570, 0.6155254), (915, 569, 0.59448206), (704, 551, 0.4790365), (1435, 473, 0.14893961), (800, 474, 0.54908377), (645, 454, 0.22723849), (1608, 473, 0.3980177), (298, 454, 0.361613), (1088, 416, 0.14296602), (452, 454, 0.32643715), (952, 435, 0.26399046)]\n",
      "Keypoints - L-Knee : [(568, 609, 0.21376629), (1319, 589, 0.18561141), (1492, 608, 0.7923422), (722, 608, 0.24735622), (1203, 608, 0.6832232), (336, 607, 0.4463177), (1049, 588, 0.64798105), (221, 569, 0.18585181), (857, 552, 0.64876467)]\n",
      "Keypoints - L-Ank : [(1318, 763, 0.12575936), (1184, 763, 0.66132087), (703, 762, 0.34463194), (336, 763, 0.6630534), (240, 725, 0.14489959), (567, 762, 0.17011085), (1415, 742, 0.7158458), (1010, 724, 0.7804575), (800, 704, 0.6917931)]\n",
      "Keypoints - R-Eye : [(1510, 376, 0.8152685), (1338, 376, 0.97546536), (857, 376, 0.9993228), (1202, 358, 0.7659994), (1030, 358, 0.8795859), (105, 357, 0.87180334), (491, 356, 0.7989144), (317, 338, 0.87622964), (664, 337, 0.9122647), (1415, 259, 0.81570935), (1280, 242, 0.84659475), (761, 241, 0.9024909), (1550, 241, 0.9691769), (625, 241, 0.9533984), (1164, 241, 0.8770442), (413, 241, 0.92912877), (895, 240, 0.79712063), (125, 240, 0.7503717), (259, 222, 0.9018225), (1049, 222, 0.92950994)]\n",
      "Keypoints - L-Eye : [(1375, 376, 0.8476553), (1530, 376, 0.94578743), (894, 376, 0.88996625), (1222, 358, 0.85643804), (1049, 357, 0.91330343), (125, 356, 0.8536809), (528, 339, 0.7413922), (336, 338, 0.94245803), (684, 337, 0.87905717), (1434, 259, 0.862556), (1299, 242, 0.86424017), (780, 241, 0.8963889), (1569, 241, 0.94308484), (645, 241, 0.92309976), (1184, 241, 0.8885832), (433, 241, 0.9393078), (914, 240, 0.81566966), (144, 223, 0.7412976), (279, 222, 0.9438673), (1068, 222, 0.92865777)]\n",
      "Keypoints - R-Ear : [(1338, 376, 0.19589114), (839, 377, 0.72644717), (1184, 376, 0.76825726), (1011, 376, 0.88614744), (67, 358, 0.7594717), (473, 356, 0.70526695), (297, 356, 0.7652054), (645, 338, 0.82680637), (1396, 260, 0.623796), (1531, 242, 0.38196173), (1146, 241, 0.30552578), (876, 241, 0.2650569), (759, 242, 0.52881134), (606, 241, 0.8461617), (394, 241, 0.8668586), (105, 241, 0.7203636), (1030, 222, 0.80869704), (240, 222, 0.8324921)]\n",
      "Keypoints - L-Ear : [(1550, 377, 0.8222542), (896, 377, 0.84314686), (1241, 376, 0.9105861), (1396, 376, 1.0009066), (1068, 376, 0.7172795), (355, 356, 0.51084983), (530, 356, 0.68295014), (702, 338, 0.8541784), (1453, 260, 0.87193197), (1319, 260, 0.77017015), (799, 242, 0.7618107), (664, 242, 0.63096535), (452, 242, 0.6003979), (1203, 241, 0.72108), (1589, 241, 0.8302617), (933, 241, 0.8501914), (1087, 222, 0.78312427), (298, 222, 0.75252295)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import argparse\n",
    "\n",
    "\n",
    "image1 = cv2.imread('../images/application/signatarai.jpg')\n",
    "\n",
    "protoFile = \"pose/coco/pose_deploy_linevec.prototxt\"\n",
    "weightsFile = \"pose/coco/pose_iter_440000.caffemodel\"\n",
    "nPoints = 18\n",
    "# COCO Output Format\n",
    "keypointsMapping = ['Nose', 'Neck', 'R-Sho', 'R-Elb', 'R-Wr', 'L-Sho', 'L-Elb', 'L-Wr', 'R-Hip', 'R-Knee', 'R-Ank', 'L-Hip', 'L-Knee', 'L-Ank', 'R-Eye', 'L-Eye', 'R-Ear', 'L-Ear']\n",
    "\n",
    "POSE_PAIRS = [[1,2], [1,5], [2,3], [3,4], [5,6], [6,7],\n",
    "              [1,8], [8,9], [9,10], [1,11], [11,12], [12,13],\n",
    "              [1,0], [0,14], [14,16], [0,15], [15,17],\n",
    "              [2,17], [5,16] ]\n",
    "\n",
    "# index of pafs correspoding to the POSE_PAIRS\n",
    "# e.g for POSE_PAIR(1,2), the PAFs are located at indices (31,32) of output, Similarly, (1,5) -> (39,40) and so on.\n",
    "mapIdx = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44],\n",
    "          [19,20], [21,22], [23,24], [25,26], [27,28], [29,30],\n",
    "          [47,48], [49,50], [53,54], [51,52], [55,56],\n",
    "          [37,38], [45,46]]\n",
    "\n",
    "colors = [ [0,100,255], [0,100,255], [0,255,255], [0,100,255], [0,255,255], [0,100,255],\n",
    "         [0,255,0], [255,200,100], [255,0,255], [0,255,0], [255,200,100], [255,0,255],\n",
    "         [0,0,255], [255,0,0], [200,200,0], [255,0,0], [200,200,0], [0,0,0]]\n",
    "\n",
    "\n",
    "def getKeypoints(probMap, threshold=0.1):\n",
    "\n",
    "    mapSmooth = cv2.GaussianBlur(probMap,(3,3),0,0)\n",
    "\n",
    "    mapMask = np.uint8(mapSmooth>threshold)\n",
    "    keypoints = []\n",
    "\n",
    "    #find the blobs\n",
    "    contours, _ = cv2.findContours(mapMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #for each blob find the maxima\n",
    "    for cnt in contours:\n",
    "        blobMask = np.zeros(mapMask.shape)\n",
    "        blobMask = cv2.fillConvexPoly(blobMask, cnt, 1)\n",
    "        maskedProbMap = mapSmooth * blobMask\n",
    "        _, maxVal, _, maxLoc = cv2.minMaxLoc(maskedProbMap)\n",
    "        keypoints.append(maxLoc + (probMap[maxLoc[1], maxLoc[0]],))\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "\n",
    "# Find valid connections between the different joints of a all persons present\n",
    "def getValidPairs(output):\n",
    "    valid_pairs = []\n",
    "    invalid_pairs = []\n",
    "    n_interp_samples = 10\n",
    "    paf_score_th = 0.1\n",
    "    conf_th = 0.7\n",
    "    # loop for every POSE_PAIR\n",
    "    for k in range(len(mapIdx)):\n",
    "        # A->B constitute a limb\n",
    "        pafA = output[0, mapIdx[k][0], :, :]\n",
    "        pafB = output[0, mapIdx[k][1], :, :]\n",
    "        pafA = cv2.resize(pafA, (frameWidth, frameHeight))\n",
    "        pafB = cv2.resize(pafB, (frameWidth, frameHeight))\n",
    "\n",
    "        # Find the keypoints for the first and second limb\n",
    "        candA = detected_keypoints[POSE_PAIRS[k][0]]\n",
    "        candB = detected_keypoints[POSE_PAIRS[k][1]]\n",
    "        nA = len(candA)\n",
    "        nB = len(candB)\n",
    "\n",
    "        # If keypoints for the joint-pair is detected\n",
    "        # check every joint in candA with every joint in candB\n",
    "        # Calculate the distance vector between the two joints\n",
    "        # Find the PAF values at a set of interpolated points between the joints\n",
    "        # Use the above formula to compute a score to mark the connection valid\n",
    "\n",
    "        if( nA != 0 and nB != 0):\n",
    "            valid_pair = np.zeros((0,3))\n",
    "            for i in range(nA):\n",
    "                max_j=-1\n",
    "                maxScore = -1\n",
    "                found = 0\n",
    "                for j in range(nB):\n",
    "                    # Find d_ij\n",
    "                    d_ij = np.subtract(candB[j][:2], candA[i][:2])\n",
    "                    norm = np.linalg.norm(d_ij)\n",
    "                    if norm:\n",
    "                        d_ij = d_ij / norm\n",
    "                    else:\n",
    "                        continue\n",
    "                    # Find p(u)\n",
    "                    interp_coord = list(zip(np.linspace(candA[i][0], candB[j][0], num=n_interp_samples),\n",
    "                                            np.linspace(candA[i][1], candB[j][1], num=n_interp_samples)))\n",
    "                    # Find L(p(u))\n",
    "                    paf_interp = []\n",
    "                    for k in range(len(interp_coord)):\n",
    "                        paf_interp.append([pafA[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))],\n",
    "                                           pafB[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))] ])\n",
    "                    # Find E\n",
    "                    paf_scores = np.dot(paf_interp, d_ij)\n",
    "                    avg_paf_score = sum(paf_scores)/len(paf_scores)\n",
    "\n",
    "                    # Check if the connection is valid\n",
    "                    # If the fraction of interpolated vectors aligned with PAF is higher then threshold -> Valid Pair\n",
    "                    if ( len(np.where(paf_scores > paf_score_th)[0]) / n_interp_samples ) > conf_th :\n",
    "                        if avg_paf_score > maxScore:\n",
    "                            max_j = j\n",
    "                            maxScore = avg_paf_score\n",
    "                            found = 1\n",
    "                # Append the connection to the list\n",
    "                if found:\n",
    "                    valid_pair = np.append(valid_pair, [[candA[i][3], candB[max_j][3], maxScore]], axis=0)\n",
    "\n",
    "            # Append the detected connections to the global list\n",
    "            valid_pairs.append(valid_pair)\n",
    "        else: # If no keypoints are detected\n",
    "            print(\"No Connection : k = {}\".format(k))\n",
    "            invalid_pairs.append(k)\n",
    "            valid_pairs.append([])\n",
    "    return valid_pairs, invalid_pairs\n",
    "\n",
    "\n",
    "\n",
    "# This function creates a list of keypoints belonging to each person\n",
    "# For each detected valid pair, it assigns the joint(s) to a person\n",
    "def getPersonwiseKeypoints(valid_pairs, invalid_pairs):\n",
    "    # the last number in each row is the overall score\n",
    "    personwiseKeypoints = -1 * np.ones((0, 19))\n",
    "\n",
    "    for k in range(len(mapIdx)):\n",
    "        if k not in invalid_pairs:\n",
    "            partAs = valid_pairs[k][:,0]\n",
    "            partBs = valid_pairs[k][:,1]\n",
    "            indexA, indexB = np.array(POSE_PAIRS[k])\n",
    "\n",
    "            for i in range(len(valid_pairs[k])):\n",
    "                found = 0\n",
    "                person_idx = -1\n",
    "                for j in range(len(personwiseKeypoints)):\n",
    "                    if personwiseKeypoints[j][indexA] == partAs[i]:\n",
    "                        person_idx = j\n",
    "                        found = 1\n",
    "                        break\n",
    "\n",
    "                if found:\n",
    "                    personwiseKeypoints[person_idx][indexB] = partBs[i]\n",
    "                    personwiseKeypoints[person_idx][-1] += keypoints_list[partBs[i].astype(int), 2] + valid_pairs[k][i][2]\n",
    "\n",
    "                # if find no partA in the subset, create a new subset\n",
    "                elif not found and k < 17:\n",
    "                    row = -1 * np.ones(19)\n",
    "                    row[indexA] = partAs[i]\n",
    "                    row[indexB] = partBs[i]\n",
    "                    # add the keypoint_scores for the two keypoints and the paf_score\n",
    "                    row[-1] = sum(keypoints_list[valid_pairs[k][i,:2].astype(int), 2]) + valid_pairs[k][i][2]\n",
    "                    personwiseKeypoints = np.vstack([personwiseKeypoints, row])\n",
    "    return personwiseKeypoints\n",
    "\n",
    "\n",
    "frameWidth = image1.shape[1]\n",
    "frameHeight = image1.shape[0]\n",
    "\n",
    "t = time.time()\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)\n",
    "# if args.device == \"cpu\":\n",
    "#     net.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)\n",
    "#     print(\"Using CPU device\")\n",
    "# elif args.device == \"gpu\":\n",
    "#     net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "#     net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "#     print(\"Using GPU device\")\n",
    "\n",
    "# Fix the input Height and get the width according to the Aspect Ratio\n",
    "inHeight = 368\n",
    "inWidth = int((inHeight/frameHeight)*frameWidth)\n",
    "\n",
    "inpBlob = cv2.dnn.blobFromImage(image1, 1.0 / 255, (inWidth, inHeight),\n",
    "                          (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "net.setInput(inpBlob)\n",
    "output = net.forward()\n",
    "print(\"Time Taken in forward pass = {}\".format(time.time() - t))\n",
    "\n",
    "detected_keypoints = []\n",
    "keypoints_list = np.zeros((0,3))\n",
    "keypoint_id = 0\n",
    "threshold = 0.1\n",
    "\n",
    "for part in range(nPoints):\n",
    "    probMap = output[0,part,:,:]\n",
    "    probMap = cv2.resize(probMap, (image1.shape[1], image1.shape[0]))\n",
    "    keypoints = getKeypoints(probMap, threshold)\n",
    "    print(\"Keypoints - {} : {}\".format(keypointsMapping[part], keypoints))\n",
    "    keypoints_with_id = []\n",
    "    for i in range(len(keypoints)):\n",
    "        keypoints_with_id.append(keypoints[i] + (keypoint_id,))\n",
    "        keypoints_list = np.vstack([keypoints_list, keypoints[i]])\n",
    "        keypoint_id += 1\n",
    "\n",
    "    detected_keypoints.append(keypoints_with_id)\n",
    "\n",
    "\n",
    "frameClone = image1.copy()\n",
    "for i in range(nPoints):\n",
    "    for j in range(len(detected_keypoints[i])):\n",
    "        cv2.circle(frameClone, detected_keypoints[i][j][0:2], 5, colors[i], -1, cv2.LINE_AA)\n",
    "cv2.imshow(\"Keypoints\",frameClone)\n",
    "\n",
    "valid_pairs, invalid_pairs = getValidPairs(output)\n",
    "personwiseKeypoints = getPersonwiseKeypoints(valid_pairs, invalid_pairs)\n",
    "\n",
    "for i in range(17):\n",
    "    for n in range(len(personwiseKeypoints)):\n",
    "        index = personwiseKeypoints[n][np.array(POSE_PAIRS[i])]\n",
    "        if -1 in index:\n",
    "            continue\n",
    "        B = np.int32(keypoints_list[index.astype(int), 0])\n",
    "        A = np.int32(keypoints_list[index.astype(int), 1])\n",
    "        cv2.line(frameClone, (B[0], A[0]), (B[1], A[1]), colors[i], 3, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Detected Pose\" , frameClone)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viola - Jones algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most powerfull to these days algo for computer vision since 2001. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 32-bit",
   "language": "python",
   "name": "python37432bitc856d1d617f0478da8cbf97a005d9730"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
